{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "import sys\n",
    "sys.path.insert(1, '../image_segmentation_keras')\n",
    "from keras_segmentation.models.config import IMAGE_ORDERING\n",
    "\n",
    "from keras_segmentation.models.model_utils import get_segmentation_model\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_conv_block(inputs, filters, pool=True, batch_norm_first=True):\n",
    "    if batch_norm_first == True:\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "    elif batch_norm_first == False:\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    if pool == True:\n",
    "        p = MaxPooling2D((2, 2))(x)\n",
    "        return [x, p]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _unet(n_classes, encoder, l1_skip_conn=True, input_height=416,\n",
    "          input_width=608):\n",
    "\n",
    "  \n",
    "    img_input, levels = encoder(\n",
    "        input_height=input_height, input_width=input_width)\n",
    "    [f1, f2, f3, f4, f5, p5] = levels\n",
    "    \n",
    "    print(\"f5\",f5.shape)\n",
    "\n",
    "    x = p5\n",
    "    \n",
    "    \"\"\" Bridge \"\"\"\n",
    "    x = unet_conv_block(x, 1024, pool=False)\n",
    "    \n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = concatenate([x, f5], axis=3)\n",
    "    x = unet_conv_block(x, 512, pool=False, batch_norm_first=True)\n",
    "    \n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = concatenate([x, f4], axis=3)\n",
    "    x = unet_conv_block(x, 512, pool=False, batch_norm_first=True)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = concatenate([x, f3], axis=3)\n",
    "    x = unet_conv_block(x, 256, pool=False, batch_norm_first=True)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = concatenate([x, f2], axis=3)\n",
    "    x = unet_conv_block(x, 128, pool=False, batch_norm_first=True)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = concatenate([x, f1], axis=3)\n",
    "    x = unet_conv_block(x, 64, pool=False, batch_norm_first=True)\n",
    "\n",
    "    x = Conv2D(n_classes, (3, 3), padding='same')(x)\n",
    "\n",
    "    model = get_segmentation_model(img_input, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMAGE_ORDERING == 'channels_first':\n",
    "    MERGE_AXIS = 1\n",
    "elif IMAGE_ORDERING == 'channels_last':\n",
    "    MERGE_AXIS = -1\n",
    "def get_vgg_encoder(input_height=224,  input_width=224, pretrained='imagenet'):\n",
    "\n",
    "    assert input_height % 32 == 0\n",
    "    assert input_width % 32 == 0\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_first':\n",
    "        img_input = Input(shape=(3, input_height, input_width))\n",
    "    elif IMAGE_ORDERING == 'channels_last':\n",
    "        img_input = Input(shape=(input_height, input_width, 3))\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "               name='block1_conv1', data_format=IMAGE_ORDERING)(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "               name='block1_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    p1 = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool',\n",
    "                     data_format=IMAGE_ORDERING)(x)\n",
    "    f1 = x\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "               name='block2_conv1', data_format=IMAGE_ORDERING)(p1)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "               name='block2_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    p2 = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool',\n",
    "                     data_format=IMAGE_ORDERING)(x)\n",
    "    f2 = x\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "               name='block3_conv1', data_format=IMAGE_ORDERING)(p2)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "               name='block3_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "               name='block3_conv3', data_format=IMAGE_ORDERING)(x)\n",
    "    p3 = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool',\n",
    "                     data_format=IMAGE_ORDERING)(x)\n",
    "    f3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block4_conv1', data_format=IMAGE_ORDERING)(p3)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block4_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block4_conv3', data_format=IMAGE_ORDERING)(x)\n",
    "    p4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool',\n",
    "                     data_format=IMAGE_ORDERING)(x)\n",
    "    f4 = x\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block5_conv1', data_format=IMAGE_ORDERING)(p4)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block5_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block5_conv3', data_format=IMAGE_ORDERING)(x)\n",
    "    p5 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool',\n",
    "                     data_format=IMAGE_ORDERING)(x)\n",
    "    f5 = x\n",
    "\n",
    "    return img_input, [f1, f2, f3, f4, f5, p5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_unet(n_classes, input_height=416, input_width=608, encoder_level=3):\n",
    "\n",
    "    model = _unet(n_classes, get_vgg_encoder,\n",
    "                  input_height=input_height, input_width=input_width)\n",
    "    model.model_name = \"vgg_unet\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f5 (None, 8, 8, 512)\n",
      "f4 (None, 16, 16, 512)\n",
      "f3 (None, 32, 32, 256)\n",
      "first concat (None, 32, 32, 512)\n",
      "(None, 32, 32, 256)\n",
      "second up (None, None, None, 128)\n",
      "f2 (None, 64, 64, 128)\n",
      "2nd concat (None, 64, 64, 256)\n",
      "third up (None, None, None, 64)\n",
      "third concat (None, 128, 128, 128)\n",
      "last (None, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "model = vgg_unet(n_classes=2,input_height=512, input_width=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5912 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5912/5912 [00:17<00:00, 333.22it/s]\n",
      "  2%|▏         | 30/1478 [00:00<00:04, 298.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Verifying validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1478/1478 [00:04<00:00, 339.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "correct\n",
      "Epoch 1/20\n",
      "5912/5912 [==============================] - 6770s 1s/step - loss: 0.6622 - accuracy: 0.7366 - val_loss: 0.4001 - val_accuracy: 0.7601\n",
      "\n",
      "Epoch 00001: saving model to pet_class_crf.h5\n",
      "Epoch 2/20\n",
      "5912/5912 [==============================] - 6645s 1s/step - loss: 0.5305 - accuracy: 0.7973 - val_loss: 0.3019 - val_accuracy: 0.8054\n",
      "\n",
      "Epoch 00002: saving model to pet_class_crf.h5\n",
      "Epoch 3/20\n",
      "5912/5912 [==============================] - 6625s 1s/step - loss: 0.4774 - accuracy: 0.8196 - val_loss: 0.3539 - val_accuracy: 0.8026\n",
      "\n",
      "Epoch 00003: saving model to pet_class_crf.h5\n",
      "Epoch 4/20\n",
      "5912/5912 [==============================] - 6604s 1s/step - loss: 0.4389 - accuracy: 0.8348 - val_loss: 0.3867 - val_accuracy: 0.8033\n",
      "\n",
      "Epoch 00004: saving model to pet_class_crf.h5\n",
      "Epoch 5/20\n",
      "5912/5912 [==============================] - 6643s 1s/step - loss: 0.4318 - accuracy: 0.8379 - val_loss: 0.4216 - val_accuracy: 0.8215\n",
      "\n",
      "Epoch 00005: saving model to pet_class_crf.h5\n",
      "Epoch 6/20\n",
      "5912/5912 [==============================] - 6646s 1s/step - loss: 0.3967 - accuracy: 0.8521 - val_loss: 0.3430 - val_accuracy: 0.8347\n",
      "\n",
      "Epoch 00006: saving model to pet_class_crf.h5\n",
      "Epoch 7/20\n",
      "5912/5912 [==============================] - 6727s 1s/step - loss: 0.3751 - accuracy: 0.8608 - val_loss: 0.3556 - val_accuracy: 0.8412\n",
      "\n",
      "Epoch 00007: saving model to pet_class_crf.h5\n",
      "Epoch 8/20\n",
      "5912/5912 [==============================] - 6673s 1s/step - loss: 0.3567 - accuracy: 0.8676 - val_loss: 0.3345 - val_accuracy: 0.8432\n",
      "\n",
      "Epoch 00008: saving model to pet_class_crf.h5\n",
      "Epoch 9/20\n",
      "5912/5912 [==============================] - 6672s 1s/step - loss: 0.3370 - accuracy: 0.8745 - val_loss: 0.2353 - val_accuracy: 0.8409\n",
      "\n",
      "Epoch 00009: saving model to pet_class_crf.h5\n",
      "Epoch 10/20\n",
      "5912/5912 [==============================] - 6685s 1s/step - loss: 0.3253 - accuracy: 0.8794 - val_loss: 0.2736 - val_accuracy: 0.8502\n",
      "\n",
      "Epoch 00010: saving model to pet_class_crf.h5\n",
      "Epoch 11/20\n",
      "5912/5912 [==============================] - 6675s 1s/step - loss: 0.3090 - accuracy: 0.8854 - val_loss: 0.3036 - val_accuracy: 0.8462\n",
      "\n",
      "Epoch 00011: saving model to pet_class_crf.h5\n",
      "Epoch 12/20\n",
      "5912/5912 [==============================] - 6667s 1s/step - loss: 0.3018 - accuracy: 0.8880 - val_loss: 0.2726 - val_accuracy: 0.8434\n",
      "\n",
      "Epoch 00012: saving model to pet_class_crf.h5\n",
      "Epoch 13/20\n",
      "5912/5912 [==============================] - 6879s 1s/step - loss: 0.2912 - accuracy: 0.8921 - val_loss: 0.3227 - val_accuracy: 0.8462\n",
      "\n",
      "Epoch 00013: saving model to pet_class_crf.h5\n",
      "Epoch 14/20\n",
      "5912/5912 [==============================] - 13023s 2s/step - loss: 0.2819 - accuracy: 0.8953 - val_loss: 0.2305 - val_accuracy: 0.8589\n",
      "\n",
      "Epoch 00014: saving model to pet_class_crf.h5\n",
      "Epoch 15/20\n",
      "5912/5912 [==============================] - 6931s 1s/step - loss: 0.2739 - accuracy: 0.8986 - val_loss: 0.2794 - val_accuracy: 0.8587\n",
      "\n",
      "Epoch 00015: saving model to pet_class_crf.h5\n",
      "Epoch 16/20\n",
      "5912/5912 [==============================] - 6656s 1s/step - loss: 0.2635 - accuracy: 0.9018 - val_loss: 0.4279 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00016: saving model to pet_class_crf.h5\n",
      "Epoch 17/20\n",
      "5912/5912 [==============================] - 6662s 1s/step - loss: 0.2899 - accuracy: 0.8925 - val_loss: 0.4085 - val_accuracy: 0.8561\n",
      "\n",
      "Epoch 00017: saving model to pet_class_crf.h5\n",
      "Epoch 18/20\n",
      "5912/5912 [==============================] - 6652s 1s/step - loss: 0.2476 - accuracy: 0.9077 - val_loss: 0.2742 - val_accuracy: 0.8543\n",
      "\n",
      "Epoch 00018: saving model to pet_class_crf.h5\n",
      "Epoch 19/20\n",
      "5912/5912 [==============================] - 6642s 1s/step - loss: 0.2451 - accuracy: 0.9085 - val_loss: 0.2178 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00019: saving model to pet_class_crf.h5\n",
      "Epoch 20/20\n",
      "5912/5912 [==============================] - 6660s 1s/step - loss: 0.2457 - accuracy: 0.9082 - val_loss: 0.3030 - val_accuracy: 0.8581\n",
      "\n",
      "Epoch 00020: saving model to pet_class_crf.h5\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_images = \"/home/maavaylon/Binary_Data/BP_lrc_training/img/\",\n",
    "    train_annotations = \"/home/maavaylon/Binary_Data/BP_lrc_training/ann/\",\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(glob(\"/home/maavaylon/Binary_Data/BP_lrc_training/img/*\")),\n",
    "    batch_size=1,\n",
    "    validate=True,\n",
    "    val_images=\"/home/maavaylon/Binary_Data/BP_lrc_testing/img/\",\n",
    "    val_annotations=\"/home/maavaylon/Binary_Data/BP_lrc_testing/ann/\",\n",
    "    val_batch_size=1,\n",
    "    val_steps_per_epoch=len(glob(\"/home/maavaylon/Binary_Data/BP_lrc_testing/img/*\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
