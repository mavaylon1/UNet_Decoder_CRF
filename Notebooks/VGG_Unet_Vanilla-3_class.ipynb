{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in loading augmentation, can't import imgaug.Please make sure it is installed.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "import sys\n",
    "sys.path.insert(1, '../image_segmentation_keras')\n",
    "from keras_segmentation.models.config import IMAGE_ORDERING\n",
    "\n",
    "from keras_segmentation.models.model_utils import get_segmentation_model\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_conv_block(inputs, filters, pool=True, batch_norm_first=True):\n",
    "    if batch_norm_first == True:\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "    elif batch_norm_first == False:\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    if pool == True:\n",
    "        p = MaxPooling2D((2, 2))(x)\n",
    "        return [x, p]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _unet(n_classes, encoder, l1_skip_conn=True, input_height=416,\n",
    "          input_width=608):\n",
    "\n",
    "  \n",
    "    img_input, levels = encoder(\n",
    "        input_height=input_height, input_width=input_width)\n",
    "    [f1, f2, f3, f4, f5] = levels\n",
    "    \n",
    "    print(\"f5\",f5.shape)\n",
    "    print(\"f4\",f4.shape)\n",
    "    print(\"f3\",f3.shape)\n",
    "    print(\"f2\",f2.shape)\n",
    "    print(\"f1\",f1.shape)\n",
    "\n",
    "    o = f5\n",
    "    \n",
    "    \"\"\" Bridge \"\"\"\n",
    "    o = unet_conv_block(o, 512, pool=False)\n",
    "    x = UpSampling2D((2, 2))(f5)\n",
    "    x = concatenate([x, f4], axis=3)\n",
    "    x = unet_conv_block(x, 512, pool=False, batch_norm_first=True)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = concatenate([x, f3], axis=3)\n",
    "    x = unet_conv_block(x, 256, pool=False, batch_norm_first=True)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = concatenate([x, f2], axis=3)\n",
    "    x = unet_conv_block(x, 128, pool=False, batch_norm_first=True)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = concatenate([x, f1], axis=3)\n",
    "    x = unet_conv_block(x, 64, pool=False, batch_norm_first=True)\n",
    "\n",
    "    x = Conv2D(n_classes, (3, 3), padding='same')(x)\n",
    "    print('b4n_class', o.shape)\n",
    "\n",
    "    model = get_segmentation_model(img_input, o)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMAGE_ORDERING == 'channels_first':\n",
    "    MERGE_AXIS = 1\n",
    "elif IMAGE_ORDERING == 'channels_last':\n",
    "    MERGE_AXIS = -1\n",
    "def get_vgg_encoder(input_height=224,  input_width=224, pretrained='imagenet'):\n",
    "\n",
    "    assert input_height % 32 == 0\n",
    "    assert input_width % 32 == 0\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_first':\n",
    "        img_input = Input(shape=(3, input_height, input_width))\n",
    "    elif IMAGE_ORDERING == 'channels_last':\n",
    "        img_input = Input(shape=(input_height, input_width, 3))\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "               name='block1_conv1', data_format=IMAGE_ORDERING)(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "               name='block1_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    p1 = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool',\n",
    "                     data_format=IMAGE_ORDERING)(x)\n",
    "    f1 = x\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "               name='block2_conv1', data_format=IMAGE_ORDERING)(p1)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "               name='block2_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    p2 = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool',\n",
    "                     data_format=IMAGE_ORDERING)(x)\n",
    "    f2 = x\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "               name='block3_conv1', data_format=IMAGE_ORDERING)(p2)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "               name='block3_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "               name='block3_conv3', data_format=IMAGE_ORDERING)(x)\n",
    "    p3 = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool',\n",
    "                     data_format=IMAGE_ORDERING)(x)\n",
    "    f3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block4_conv1', data_format=IMAGE_ORDERING)(p3)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block4_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block4_conv3', data_format=IMAGE_ORDERING)(x)\n",
    "    p4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool',\n",
    "                     data_format=IMAGE_ORDERING)(x)\n",
    "    f4 = x\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block5_conv1', data_format=IMAGE_ORDERING)(p4)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block5_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block5_conv3', data_format=IMAGE_ORDERING)(x)\n",
    "    f5 = x\n",
    "\n",
    "#     if pretrained == 'imagenet':\n",
    "#         VGG_Weights_path = keras.utils.get_file(\n",
    "#             pretrained_url.split(\"/\")[-1], pretrained_url)\n",
    "#         Model(img_input, x).load_weights(VGG_Weights_path)\n",
    "\n",
    "    return img_input, [f1, f2, f3, f4, f5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_unet(n_classes, input_height=416, input_width=608, encoder_level=3):\n",
    "\n",
    "    model = _unet(n_classes, get_vgg_encoder,\n",
    "                  input_height=input_height, input_width=input_width)\n",
    "    model.model_name = \"vgg_unet\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f5 (None, 16, 16, 512)\n",
      "f4 (None, 32, 32, 512)\n",
      "f3 (None, 64, 64, 256)\n",
      "f2 (None, 128, 128, 128)\n",
      "f1 (None, 256, 256, 64)\n",
      "b4n_class (None, 16, 16, 512)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 256, 512)          0         \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 256, 512)          0         \n",
      "=================================================================\n",
      "Total params: 19,438,400\n",
      "Trainable params: 19,436,352\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = vgg_unet(n_classes=3,input_height=256, input_width=256)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5912 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5912/5912 [00:17<00:00, 333.22it/s]\n",
      "  2%|▏         | 30/1478 [00:00<00:04, 298.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Verifying validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1478/1478 [00:04<00:00, 339.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "correct\n",
      "Epoch 1/20\n",
      "5912/5912 [==============================] - 6770s 1s/step - loss: 0.6622 - accuracy: 0.7366 - val_loss: 0.4001 - val_accuracy: 0.7601\n",
      "\n",
      "Epoch 00001: saving model to pet_class_crf.h5\n",
      "Epoch 2/20\n",
      "5912/5912 [==============================] - 6645s 1s/step - loss: 0.5305 - accuracy: 0.7973 - val_loss: 0.3019 - val_accuracy: 0.8054\n",
      "\n",
      "Epoch 00002: saving model to pet_class_crf.h5\n",
      "Epoch 3/20\n",
      "5912/5912 [==============================] - 6625s 1s/step - loss: 0.4774 - accuracy: 0.8196 - val_loss: 0.3539 - val_accuracy: 0.8026\n",
      "\n",
      "Epoch 00003: saving model to pet_class_crf.h5\n",
      "Epoch 4/20\n",
      "5912/5912 [==============================] - 6604s 1s/step - loss: 0.4389 - accuracy: 0.8348 - val_loss: 0.3867 - val_accuracy: 0.8033\n",
      "\n",
      "Epoch 00004: saving model to pet_class_crf.h5\n",
      "Epoch 5/20\n",
      "5912/5912 [==============================] - 6643s 1s/step - loss: 0.4318 - accuracy: 0.8379 - val_loss: 0.4216 - val_accuracy: 0.8215\n",
      "\n",
      "Epoch 00005: saving model to pet_class_crf.h5\n",
      "Epoch 6/20\n",
      "5912/5912 [==============================] - 6646s 1s/step - loss: 0.3967 - accuracy: 0.8521 - val_loss: 0.3430 - val_accuracy: 0.8347\n",
      "\n",
      "Epoch 00006: saving model to pet_class_crf.h5\n",
      "Epoch 7/20\n",
      "5912/5912 [==============================] - 6727s 1s/step - loss: 0.3751 - accuracy: 0.8608 - val_loss: 0.3556 - val_accuracy: 0.8412\n",
      "\n",
      "Epoch 00007: saving model to pet_class_crf.h5\n",
      "Epoch 8/20\n",
      "5912/5912 [==============================] - 6673s 1s/step - loss: 0.3567 - accuracy: 0.8676 - val_loss: 0.3345 - val_accuracy: 0.8432\n",
      "\n",
      "Epoch 00008: saving model to pet_class_crf.h5\n",
      "Epoch 9/20\n",
      "5912/5912 [==============================] - 6672s 1s/step - loss: 0.3370 - accuracy: 0.8745 - val_loss: 0.2353 - val_accuracy: 0.8409\n",
      "\n",
      "Epoch 00009: saving model to pet_class_crf.h5\n",
      "Epoch 10/20\n",
      "5912/5912 [==============================] - 6685s 1s/step - loss: 0.3253 - accuracy: 0.8794 - val_loss: 0.2736 - val_accuracy: 0.8502\n",
      "\n",
      "Epoch 00010: saving model to pet_class_crf.h5\n",
      "Epoch 11/20\n",
      "5912/5912 [==============================] - 6675s 1s/step - loss: 0.3090 - accuracy: 0.8854 - val_loss: 0.3036 - val_accuracy: 0.8462\n",
      "\n",
      "Epoch 00011: saving model to pet_class_crf.h5\n",
      "Epoch 12/20\n",
      "5912/5912 [==============================] - 6667s 1s/step - loss: 0.3018 - accuracy: 0.8880 - val_loss: 0.2726 - val_accuracy: 0.8434\n",
      "\n",
      "Epoch 00012: saving model to pet_class_crf.h5\n",
      "Epoch 13/20\n",
      "5912/5912 [==============================] - 6879s 1s/step - loss: 0.2912 - accuracy: 0.8921 - val_loss: 0.3227 - val_accuracy: 0.8462\n",
      "\n",
      "Epoch 00013: saving model to pet_class_crf.h5\n",
      "Epoch 14/20\n",
      "5912/5912 [==============================] - 13023s 2s/step - loss: 0.2819 - accuracy: 0.8953 - val_loss: 0.2305 - val_accuracy: 0.8589\n",
      "\n",
      "Epoch 00014: saving model to pet_class_crf.h5\n",
      "Epoch 15/20\n",
      "5912/5912 [==============================] - 6931s 1s/step - loss: 0.2739 - accuracy: 0.8986 - val_loss: 0.2794 - val_accuracy: 0.8587\n",
      "\n",
      "Epoch 00015: saving model to pet_class_crf.h5\n",
      "Epoch 16/20\n",
      "5912/5912 [==============================] - 6656s 1s/step - loss: 0.2635 - accuracy: 0.9018 - val_loss: 0.4279 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00016: saving model to pet_class_crf.h5\n",
      "Epoch 17/20\n",
      "5912/5912 [==============================] - 6662s 1s/step - loss: 0.2899 - accuracy: 0.8925 - val_loss: 0.4085 - val_accuracy: 0.8561\n",
      "\n",
      "Epoch 00017: saving model to pet_class_crf.h5\n",
      "Epoch 18/20\n",
      "5912/5912 [==============================] - 6652s 1s/step - loss: 0.2476 - accuracy: 0.9077 - val_loss: 0.2742 - val_accuracy: 0.8543\n",
      "\n",
      "Epoch 00018: saving model to pet_class_crf.h5\n",
      "Epoch 19/20\n",
      "5912/5912 [==============================] - 6642s 1s/step - loss: 0.2451 - accuracy: 0.9085 - val_loss: 0.2178 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00019: saving model to pet_class_crf.h5\n",
      "Epoch 20/20\n",
      "5912/5912 [==============================] - 6660s 1s/step - loss: 0.2457 - accuracy: 0.9082 - val_loss: 0.3030 - val_accuracy: 0.8581\n",
      "\n",
      "Epoch 00020: saving model to pet_class_crf.h5\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_images =  \"/home/maavaylon/Data1/train/img/\",\n",
    "    train_annotations = \"/home/maavaylon/Data1/train/ann/\",\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(glob(\"/home/maavaylon/Data1/train/img/*\")),\n",
    "    batch_size=1,\n",
    "    validate=True,\n",
    "    val_images=\"/home/maavaylon/Data1/test/img/\",\n",
    "    val_annotations=\"/home/maavaylon/Data1/test/ann/\",\n",
    "    val_batch_size=1,\n",
    "    val_steps_per_epoch=len(glob(\"/home/maavaylon/Data1/test/img/*\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
