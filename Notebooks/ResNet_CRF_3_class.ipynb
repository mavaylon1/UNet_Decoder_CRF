{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "sys.path.insert(1, '../image_segmentation_keras')\n",
    "from keras_segmentation.models.config import IMAGE_ORDERING\n",
    "\n",
    "from keras_segmentation.models.model_utils import get_segmentation_model\n",
    "from glob import glob\n",
    "from crfrnn_layer import CrfRnnLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height=256 #416\n",
    "input_width=256 #608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_conv_block(inputs, filters, pool=True, batch_norm_first=True):\n",
    "    if batch_norm_first == True:\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "    elif batch_norm_first == False:\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    if pool == True:\n",
    "        p = MaxPooling2D((2, 2))(x)\n",
    "        return [x, p]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _unet(n_classes, encoder, l1_skip_conn=True, input_height=416,\n",
    "          input_width=608):\n",
    "\n",
    "    img_input, levels = encoder(\n",
    "        input_height=input_height, input_width=input_width)\n",
    "    [f1, f2, f3, f4, f5] = levels\n",
    "    \n",
    "    print(\"f5\",f5.shape)\n",
    "\n",
    "    o = f5\n",
    "    \n",
    "    \"\"\" Bridge \"\"\"\n",
    "    o = unet_conv_block(o, 2048, pool=False)\n",
    "    \n",
    "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (concatenate([o, f4], axis=3))\n",
    "    o = unet_conv_block(o, 1024, pool=False)\n",
    "    \n",
    "    o = UpSampling2D((2, 2), interpolation=\"bilinear\")(o)\n",
    "    o = (concatenate([o, f3], axis=3))\n",
    "    o = unet_conv_block(o, 512, pool=False)\n",
    "    \n",
    "\n",
    "    o = UpSampling2D((2, 2), interpolation=\"bilinear\")(o)\n",
    "    o = (concatenate([o, f2], axis=3))\n",
    "    o = unet_conv_block(o, 256, pool=False)\n",
    "\n",
    "\n",
    "    o = UpSampling2D((2, 2), interpolation=\"bilinear\")(o)\n",
    "    o = (concatenate([o, f1], axis=3))\n",
    "    o = unet_conv_block(o, 64, pool=False)\n",
    "    \n",
    "    o = UpSampling2D((2, 2), interpolation=\"bilinear\")(o)\n",
    "    o = Conv2D(n_classes, (3, 3), padding='same',\n",
    "               data_format=IMAGE_ORDERING)(o)\n",
    "\n",
    "    crf_output = CrfRnnLayer(image_dims=(input_height, input_width),\n",
    "                         num_classes=n_classes,\n",
    "                         theta_alpha=160.,\n",
    "                         theta_beta=3.,\n",
    "                         theta_gamma=3.,\n",
    "                         num_iterations=10,\n",
    "                         name='crfrnn')([o, img_input])\n",
    "    model = get_segmentation_model(img_input, crf_output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMAGE_ORDERING == 'channels_first':\n",
    "    MERGE_AXIS = 1\n",
    "elif IMAGE_ORDERING == 'channels_last':\n",
    "    MERGE_AXIS = -1\n",
    "\n",
    "def one_side_pad(x):\n",
    "    x = ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING)(x)\n",
    "    if IMAGE_ORDERING == 'channels_first':\n",
    "        x = Lambda(lambda x: x[:, :, :-1, :-1])(x)\n",
    "    elif IMAGE_ORDERING == 'channels_last':\n",
    "        x = Lambda(lambda x: x[:, :-1, :-1, :])(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at\n",
    "                     main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block,\n",
    "               strides=(2, 2)):\n",
    "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at\n",
    "                     main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with\n",
    "    strides=(2,2) and the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING, strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "                      strides=strides, name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "#     print(shortcut.shape)\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_resnet50_encoder(input_height,  input_width,\n",
    "                        \n",
    "                         include_top=True, \n",
    "                         input_tensor=None, input_shape=None,\n",
    "                         pooling=None,\n",
    "                         classes=1000):\n",
    "    print(input_height)\n",
    "    assert input_height % 32 == 0\n",
    "    assert input_width % 32 == 0\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_first':\n",
    "        img_input = Input(shape=(3, input_height, input_width))\n",
    "    elif IMAGE_ORDERING == 'channels_last':\n",
    "        img_input = Input(shape=(input_height, input_width, 3))\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = ZeroPadding2D((3, 3), data_format=IMAGE_ORDERING)(img_input)\n",
    "    x = Conv2D(64, (7, 7), data_format=IMAGE_ORDERING,\n",
    "               strides=(2, 2), name='conv1')(x)\n",
    "    f1 = x\n",
    "\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), data_format=IMAGE_ORDERING, strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "    f2 = one_side_pad(x)\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "    f3 = x\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "    f4 = x\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    f5 = x\n",
    "\n",
    "    return img_input, [f1, f2, f3, f4, f5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50_unet(n_classes, input_height=512, input_width=512,\n",
    "                  encoder_level=3):\n",
    "\n",
    "    model = _unet(n_classes, get_resnet50_encoder,\n",
    "                  input_height=input_height, input_width=input_width)\n",
    "    model.model_name = \"resnet50_unet\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "f5 (None, 8, 8, 2048)\n"
     ]
    }
   ],
   "source": [
    "model = resnet50_unet(n_classes=3 ,  input_height=256, input_width=256  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/Users/mavaylon/Research/pet_weights/RESNET50_CRF_PET/RESNET50_CRF_PET.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5912 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5912/5912 [00:17<00:00, 343.36it/s]\n",
      "  2%|▏         | 35/1478 [00:00<00:04, 349.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Verifying validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1478/1478 [00:04<00:00, 335.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "fit\n",
      "Epoch 1/20\n",
      "5912/5912 [==============================] - 23746s 4s/step - loss: 0.2444 - accuracy: 0.9097 - val_loss: 0.4442 - val_accuracy: 0.8524\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85237, saving model to pet_class_crf.h5\n",
      "Epoch 2/20\n",
      "5912/5912 [==============================] - 22810s 4s/step - loss: 0.2363 - accuracy: 0.9124 - val_loss: 0.4393 - val_accuracy: 0.8665\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.85237 to 0.86645, saving model to pet_class_crf.h5\n",
      "Epoch 3/20\n",
      "5912/5912 [==============================] - 22465s 4s/step - loss: 0.2321 - accuracy: 0.9141 - val_loss: 0.8084 - val_accuracy: 0.8632\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.86645\n",
      "Epoch 4/20\n",
      "5912/5912 [==============================] - 22172s 4s/step - loss: 0.2275 - accuracy: 0.9157 - val_loss: 0.4272 - val_accuracy: 0.8591\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.86645\n",
      "Epoch 5/20\n",
      "5912/5912 [==============================] - 22687s 4s/step - loss: 0.2247 - accuracy: 0.9167 - val_loss: 0.4040 - val_accuracy: 0.8722\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.86645 to 0.87224, saving model to pet_class_crf.h5\n",
      "Epoch 6/20\n",
      "5912/5912 [==============================] - 22949s 4s/step - loss: 0.2141 - accuracy: 0.9202 - val_loss: 0.5364 - val_accuracy: 0.8665\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.87224\n",
      "Epoch 7/20\n",
      "5912/5912 [==============================] - 22396s 4s/step - loss: 0.2121 - accuracy: 0.9208 - val_loss: 0.6459 - val_accuracy: 0.8457\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.87224\n",
      "Epoch 8/20\n",
      "5912/5912 [==============================] - 22194s 4s/step - loss: 0.2004 - accuracy: 0.9251 - val_loss: 0.4159 - val_accuracy: 0.8567\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.87224\n",
      "Epoch 9/20\n",
      "5912/5912 [==============================] - 22969s 4s/step - loss: 0.1965 - accuracy: 0.9263 - val_loss: 0.4879 - val_accuracy: 0.8606\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.87224\n",
      "Epoch 10/20\n",
      "5912/5912 [==============================] - 22814s 4s/step - loss: 0.1966 - accuracy: 0.9265 - val_loss: 0.4975 - val_accuracy: 0.8692\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.87224\n",
      "Epoch 11/20\n",
      "5912/5912 [==============================] - 22268s 4s/step - loss: 0.1879 - accuracy: 0.9294 - val_loss: 0.3594 - val_accuracy: 0.8666\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.87224\n",
      "Epoch 12/20\n",
      "4136/5912 [===================>..........] - ETA: 1:46:25 - loss: 0.1836 - accuracy: 0.9310"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_images =  \"/Users/mavaylon/Research/Data1/train/img/\",\n",
    "    train_annotations = \"/Users/mavaylon/Research/Data1/train/ann/\",\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(glob(\"/Users/mavaylon/Research/Data1/train/img/*\")),\n",
    "    batch_size=1,\n",
    "    validate=True,\n",
    "    val_images=\"/Users/mavaylon/Research/Data1/test/img/\",\n",
    "    val_annotations=\"/Users/mavaylon/Research/Data1/test/ann/\",\n",
    "    val_batch_size=1,\n",
    "    val_steps_per_epoch=len(glob(\"/Users/mavaylon/Research/Data1/test/img/*\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
