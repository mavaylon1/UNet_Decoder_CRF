{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in loading augmentation, can't import imgaug.Please make sure it is installed.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "sys.path.insert(1, '../image_segmentation_keras')\n",
    "from keras_segmentation.models.config import IMAGE_ORDERING\n",
    "\n",
    "from keras_segmentation.models.model_utils import get_segmentation_model\n",
    "from glob import glob\n",
    "from crfrnn_layer import CrfRnnLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height=256 #416\n",
    "input_width=256 #608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_conv_block(inputs, filters, pool=True, batch_norm_first=True):\n",
    "    if batch_norm_first == True:\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "    elif batch_norm_first == False:\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    if pool == True:\n",
    "        p = MaxPooling2D((2, 2))(x)\n",
    "        return [x, p]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _unet(n_classes, encoder, l1_skip_conn=True, input_height=416,\n",
    "          input_width=608):\n",
    "\n",
    "    img_input, levels = encoder(\n",
    "        input_height=input_height, input_width=input_width)\n",
    "    [f1, f2, f3, f4, f5] = levels\n",
    "    \n",
    "    print(\"f5\",f5.shape)\n",
    "\n",
    "    o = f5\n",
    "    \n",
    "    \"\"\" Bridge \"\"\"\n",
    "    o = unet_conv_block(o, 2048, pool=False)\n",
    "    \n",
    "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (concatenate([o, f4], axis=3))\n",
    "    o = unet_conv_block(o, 1024, pool=False)\n",
    "    \n",
    "    o = UpSampling2D((2, 2), interpolation=\"bilinear\")(o)\n",
    "    o = (concatenate([o, f3], axis=3))\n",
    "    o = unet_conv_block(o, 512, pool=False)\n",
    "    \n",
    "\n",
    "    o = UpSampling2D((2, 2), interpolation=\"bilinear\")(o)\n",
    "    o = (concatenate([o, f2], axis=3))\n",
    "    o = unet_conv_block(o, 256, pool=False)\n",
    "\n",
    "\n",
    "    o = UpSampling2D((2, 2), interpolation=\"bilinear\")(o)\n",
    "    o = (concatenate([o, f1], axis=3))\n",
    "    o = unet_conv_block(o, 64, pool=False)\n",
    "    \n",
    "    o = UpSampling2D((2, 2), interpolation=\"bilinear\")(o)\n",
    "    o = Conv2D(n_classes, (3, 3), padding='same',\n",
    "               data_format=IMAGE_ORDERING)(o)\n",
    "\n",
    "    crf_output = CrfRnnLayer(image_dims=(input_height, input_width),\n",
    "                         num_classes=n_classes,\n",
    "                         theta_alpha=160.,\n",
    "                         theta_beta=3.,\n",
    "                         theta_gamma=3.,\n",
    "                         num_iterations=10,\n",
    "                         name='crfrnn')([o, img_input])\n",
    "    model = get_segmentation_model(img_input, crf_output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMAGE_ORDERING == 'channels_first':\n",
    "    MERGE_AXIS = 1\n",
    "elif IMAGE_ORDERING == 'channels_last':\n",
    "    MERGE_AXIS = -1\n",
    "\n",
    "def one_side_pad(x):\n",
    "    x = ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING)(x)\n",
    "    if IMAGE_ORDERING == 'channels_first':\n",
    "        x = Lambda(lambda x: x[:, :, :-1, :-1])(x)\n",
    "    elif IMAGE_ORDERING == 'channels_last':\n",
    "        x = Lambda(lambda x: x[:, :-1, :-1, :])(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at\n",
    "                     main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block,\n",
    "               strides=(2, 2)):\n",
    "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at\n",
    "                     main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with\n",
    "    strides=(2,2) and the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING, strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "                      strides=strides, name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "#     print(shortcut.shape)\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_resnet50_encoder(input_height,  input_width,\n",
    "                        \n",
    "                         include_top=True, \n",
    "                         input_tensor=None, input_shape=None,\n",
    "                         pooling=None,\n",
    "                         classes=1000):\n",
    "    print(input_height)\n",
    "    assert input_height % 32 == 0\n",
    "    assert input_width % 32 == 0\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_first':\n",
    "        img_input = Input(shape=(3, input_height, input_width))\n",
    "    elif IMAGE_ORDERING == 'channels_last':\n",
    "        img_input = Input(shape=(input_height, input_width, 3))\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = ZeroPadding2D((3, 3), data_format=IMAGE_ORDERING)(img_input)\n",
    "    x = Conv2D(64, (7, 7), data_format=IMAGE_ORDERING,\n",
    "               strides=(2, 2), name='conv1')(x)\n",
    "    f1 = x\n",
    "\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), data_format=IMAGE_ORDERING, strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "    f2 = one_side_pad(x)\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "    f3 = x\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "    f4 = x\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    f5 = x\n",
    "\n",
    "    return img_input, [f1, f2, f3, f4, f5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50_unet(n_classes, input_height=512, input_width=512,\n",
    "                  encoder_level=3):\n",
    "\n",
    "    model = _unet(n_classes, get_resnet50_encoder,\n",
    "                  input_height=input_height, input_width=input_width)\n",
    "    model.model_name = \"resnet50_unet\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "f5 (None, 8, 8, 2048)\n"
     ]
    }
   ],
   "source": [
    "model = resnet50_unet(n_classes=3 ,  input_height=256, input_width=256  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5912/5912 [00:18<00:00, 326.21it/s]\n",
      "  2%|▏         | 32/1478 [00:00<00:04, 312.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Verifying validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1478/1478 [00:04<00:00, 334.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "fit\n",
      "Epoch 1/20\n",
      "5912/5912 [==============================] - 19533s 3s/step - loss: 0.6529 - accuracy: 0.7421 - val_loss: 1.0690 - val_accuracy: 0.7629\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76295, saving model to pet_class_crf.h5\n",
      "Epoch 2/20\n",
      "5912/5912 [==============================] - 19391s 3s/step - loss: 0.5743 - accuracy: 0.7818 - val_loss: 1.0068 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.76295 to 0.78612, saving model to pet_class_crf.h5\n",
      "Epoch 3/20\n",
      "5912/5912 [==============================] - 19258s 3s/step - loss: 0.5264 - accuracy: 0.8022 - val_loss: 0.7134 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78612 to 0.80215, saving model to pet_class_crf.h5\n",
      "Epoch 4/20\n",
      "5912/5912 [==============================] - 19187s 3s/step - loss: 0.4895 - accuracy: 0.8181 - val_loss: 0.9393 - val_accuracy: 0.7984\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.80215\n",
      "Epoch 5/20\n",
      "5912/5912 [==============================] - 20283s 3s/step - loss: 0.4562 - accuracy: 0.8316 - val_loss: 0.4486 - val_accuracy: 0.8142\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.80215 to 0.81418, saving model to pet_class_crf.h5\n",
      "Epoch 6/20\n",
      "5912/5912 [==============================] - 19583s 3s/step - loss: 0.4335 - accuracy: 0.8412 - val_loss: 0.3950 - val_accuracy: 0.8340\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.81418 to 0.83397, saving model to pet_class_crf.h5\n",
      "Epoch 7/20\n",
      "5912/5912 [==============================] - 19292s 3s/step - loss: 0.4120 - accuracy: 0.8495 - val_loss: 0.2815 - val_accuracy: 0.8326\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.83397\n",
      "Epoch 8/20\n",
      "5912/5912 [==============================] - 19223s 3s/step - loss: 0.3934 - accuracy: 0.8567 - val_loss: 0.3376 - val_accuracy: 0.8445\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.83397 to 0.84454, saving model to pet_class_crf.h5\n",
      "Epoch 9/20\n",
      "5912/5912 [==============================] - 19412s 3s/step - loss: 0.3809 - accuracy: 0.8618 - val_loss: 0.2515 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.84454 to 0.84825, saving model to pet_class_crf.h5\n",
      "Epoch 10/20\n",
      "5912/5912 [==============================] - 19657s 3s/step - loss: 0.3624 - accuracy: 0.8688 - val_loss: 0.4078 - val_accuracy: 0.8339\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.84825\n",
      "Epoch 11/20\n",
      "5912/5912 [==============================] - 19663s 3s/step - loss: 0.3508 - accuracy: 0.8732 - val_loss: 0.4410 - val_accuracy: 0.8384\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.84825\n",
      "Epoch 12/20\n",
      "5912/5912 [==============================] - 19313s 3s/step - loss: 0.3436 - accuracy: 0.8760 - val_loss: 0.3348 - val_accuracy: 0.8473\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.84825\n",
      "Epoch 13/20\n",
      "5912/5912 [==============================] - 19276s 3s/step - loss: 0.3297 - accuracy: 0.8813 - val_loss: 0.2736 - val_accuracy: 0.8386\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84825\n",
      "Epoch 14/20\n",
      "5912/5912 [==============================] - 20068s 3s/step - loss: 0.3160 - accuracy: 0.8861 - val_loss: 0.3005 - val_accuracy: 0.8529\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.84825 to 0.85292, saving model to pet_class_crf.h5\n",
      "Epoch 15/20\n",
      "5912/5912 [==============================] - 19349s 3s/step - loss: 0.3131 - accuracy: 0.8871 - val_loss: 0.2777 - val_accuracy: 0.8396\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.85292\n",
      "Epoch 16/20\n",
      "5912/5912 [==============================] - 19315s 3s/step - loss: 0.3040 - accuracy: 0.8905 - val_loss: 0.2260 - val_accuracy: 0.8586\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.85292 to 0.85861, saving model to pet_class_crf.h5\n",
      "Epoch 17/20\n",
      "5912/5912 [==============================] - 19294s 3s/step - loss: 0.2930 - accuracy: 0.8943 - val_loss: 0.3590 - val_accuracy: 0.8427\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.85861\n",
      "Epoch 18/20\n",
      "5912/5912 [==============================] - 19272s 3s/step - loss: 0.2842 - accuracy: 0.8974 - val_loss: 0.2638 - val_accuracy: 0.8505\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.85861\n",
      "Epoch 19/20\n",
      "5912/5912 [==============================] - 19190s 3s/step - loss: 0.2748 - accuracy: 0.9007 - val_loss: 0.2571 - val_accuracy: 0.8628\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.85861 to 0.86281, saving model to pet_class_crf.h5\n",
      "Epoch 20/20\n",
      "5912/5912 [==============================] - 19218s 3s/step - loss: 0.2666 - accuracy: 0.9037 - val_loss: 0.3294 - val_accuracy: 0.8469\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.86281\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_images =  \"/Users/mavaylon/Research/Data1/train/img/\",\n",
    "    train_annotations = \"/Users/mavaylon/Research/Data1/train/ann/\",\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(glob(\"/Users/mavaylon/Research/Data1/train/img/*\")),\n",
    "    batch_size=1,\n",
    "    validate=True,\n",
    "    val_images=\"/Users/mavaylon/Research/Data1/test/img/\",\n",
    "    val_annotations=\"/Users/mavaylon/Research/Data1/test/ann/\",\n",
    "    val_batch_size=1,\n",
    "    val_steps_per_epoch=len(glob(\"/Users/mavaylon/Research/Data1/test/img/*\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
