{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "sys.path.insert(1, '../image_segmentation_keras')\n",
    "from keras_segmentation.models.config import IMAGE_ORDERING\n",
    "\n",
    "from keras_segmentation.models.model_utils import get_segmentation_model\n",
    "from glob import glob\n",
    "from crfrnn_layer import CrfRnnLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels, height, width = 3, 256, 256\n",
    "n_classes = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_side_pad(x):\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "    x = Lambda(lambda x: x[:, :-1, :-1, :])(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 3)\n",
      "(None, None, None, 3)\n",
      "(None, None, None, 3)\n",
      "(None, None, None, 3)\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "input_shape = (height, width, 3)\n",
    "img_input = Input(shape=input_shape)\n",
    "print(img_input.shape)\n",
    "# Add plenty of zero padding\n",
    "x = ZeroPadding2D(padding=(100, 100))(img_input)\n",
    "\n",
    "# VGG-16 convolution block 1\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='valid', name='conv1_1')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "# VGG-16 convolution block 2\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_1')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool2', padding='same')(x)\n",
    "\n",
    "# VGG-16 convolution block 3\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_1')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool3', padding='same')(x)\n",
    "pool3 = x\n",
    "\n",
    "# VGG-16 convolution block 4\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_1')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_2')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool4', padding='same')(x)\n",
    "pool4 = x\n",
    "\n",
    "# VGG-16 convolution block 5\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_1')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_2')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool5', padding='same')(x)\n",
    "\n",
    "# Fully-connected layers converted to convolution layers\n",
    "x = Conv2D(4096, (7, 7), activation='relu', padding='valid', name='fc6')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(4096, (1, 1), activation='relu', padding='valid', name='fc7')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(n_classes, (1, 1), padding='valid', name='score-fr')(x)\n",
    "\n",
    "# Deconvolution\n",
    "score2 = Conv2DTranspose(n_classes, (4, 4), strides=2, name='score2')(x)\n",
    "print(score2.shape)\n",
    "# Skip connections from pool4\n",
    "score_pool4 = Conv2D(n_classes, (1, 1), name='score-pool4')(pool4)\n",
    "score_pool4c = Cropping2D((5, 5))(score_pool4)\n",
    "score_pool4c = one_side_pad(score_pool4c)\n",
    "score_fused = Add()([score2, score_pool4c])\n",
    "score4 = Conv2DTranspose(n_classes, (4, 4), strides=2, name='score4', use_bias=False)(score_fused)\n",
    "print(score4.shape)\n",
    "\n",
    "# Skip connections from pool3\n",
    "score_pool3 = Conv2D(n_classes, (1, 1), name='score-pool3')(pool3)\n",
    "score_pool3c = Cropping2D((8, 8))(score_pool3)\n",
    "score_pool3c = one_side_pad(score_pool3c)\n",
    "\n",
    "# Fuse things together\n",
    "score_final = Add()([score4, score_pool3c])\n",
    "\n",
    "# Final up-sampling and cropping\n",
    "upsample = Conv2DTranspose(n_classes, (16, 16), strides=8, name='upsample', use_bias=False)(score_final)\n",
    "upscore = Cropping2D(((44, 44), (44, 44)))(upsample)\n",
    "print(upscore.shape)\n",
    "output = CrfRnnLayer(image_dims=(height, width),\n",
    "                     num_classes=n_classes,\n",
    "                     theta_alpha=160.,\n",
    "                     theta_beta=3.,\n",
    "                     theta_gamma=3.,\n",
    "                     num_iterations=10,\n",
    "                     name='crfrnn')([upscore, img_input])\n",
    "\n",
    "model= get_segmentation_model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5912/5912 [00:23<00:00, 254.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Verifying validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1478/1478 [00:06<00:00, 213.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "fit\n",
      "Epoch 1/20\n",
      "5912/5912 [==============================] - 34827s 6s/step - loss: 0.7016 - accuracy: 0.7345 - val_loss: 0.5418 - val_accuracy: 0.7643\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76432, saving model to pet_class_crf.h5\n",
      "Epoch 2/20\n",
      "5912/5912 [==============================] - 28794s 5s/step - loss: 0.6506 - accuracy: 0.7566 - val_loss: 0.5329 - val_accuracy: 0.7583\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.76432\n",
      "Epoch 3/20\n",
      "5912/5912 [==============================] - 26812s 5s/step - loss: 0.6405 - accuracy: 0.7605 - val_loss: 0.6104 - val_accuracy: 0.7542\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.76432\n",
      "Epoch 4/20\n",
      "5912/5912 [==============================] - 27313s 5s/step - loss: 0.6289 - accuracy: 0.7586 - val_loss: 0.4878 - val_accuracy: 0.7782\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.76432 to 0.77823, saving model to pet_class_crf.h5\n",
      "Epoch 5/20\n",
      "5912/5912 [==============================] - 26907s 5s/step - loss: 0.5823 - accuracy: 0.7793 - val_loss: 0.4706 - val_accuracy: 0.7991\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.77823 to 0.79913, saving model to pet_class_crf.h5\n",
      "Epoch 6/20\n",
      "5912/5912 [==============================] - 27171s 5s/step - loss: 0.5414 - accuracy: 0.7956 - val_loss: 0.5064 - val_accuracy: 0.8002\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.79913 to 0.80025, saving model to pet_class_crf.h5\n",
      "Epoch 7/20\n",
      "5912/5912 [==============================] - 27944s 5s/step - loss: 0.5222 - accuracy: 0.8034 - val_loss: 0.4628 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.80025 to 0.81912, saving model to pet_class_crf.h5\n",
      "Epoch 8/20\n",
      "2806/5912 [=============>................] - ETA: 3:51:40 - loss: 0.5123 - accuracy: 0.8074"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_images =  \"/Users/mavaylon/Research/Data1/train/img/\",\n",
    "    train_annotations = \"/Users/mavaylon/Research/Data1/train/ann/\",\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(glob(\"/Users/mavaylon/Research/Data1/train/img/*\")),\n",
    "    batch_size=1,\n",
    "    validate=True,\n",
    "    val_images=\"/Users/mavaylon/Research/Data1/test/img/\",\n",
    "    val_annotations=\"/Users/mavaylon/Research/Data1/test/ann/\",\n",
    "    val_batch_size=1,\n",
    "    val_steps_per_epoch=len(glob(\"/Users/mavaylon/Research/Data1/test/img/*\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
