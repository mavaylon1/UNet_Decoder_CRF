{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "sys.path.insert(1, '../image_segmentation_keras')\n",
    "from keras_segmentation.models.config import IMAGE_ORDERING\n",
    "\n",
    "from keras_segmentation.models.model_utils import get_segmentation_model\n",
    "from glob import glob\n",
    "from crfrnn_layer import CrfRnnLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height=256\n",
    "input_width=256 \n",
    "n_classes = 3\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#residual unet adapted from:\n",
    "#https://github.com/nikhilroxtomar/Deep-Residual-Unet/blob/master/Deep%20Residual%20UNet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_act(x, act=True):\n",
    "    x = BatchNormalization()(x)\n",
    "    if act == True:\n",
    "        x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    conv = bn_act(x)\n",
    "    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
    "    return conv\n",
    "\n",
    "def stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
    "    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
    "    \n",
    "    shortcut = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
    "    shortcut = bn_act(shortcut, act=False)\n",
    "    \n",
    "    output = Add()([conv, shortcut])\n",
    "    return output\n",
    "\n",
    "def residual_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
    "    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n",
    "    \n",
    "    shortcut = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
    "    shortcut = bn_act(shortcut, act=False)\n",
    "    \n",
    "    output = Add()([shortcut, res])\n",
    "    return output\n",
    "\n",
    "def upsample_concat_block(x, xskip):\n",
    "    u = UpSampling2D((2, 2))(x)\n",
    "    c = Concatenate()([u, xskip])\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d_30/Relu:0\", shape=(None, 256, 256, 3), dtype=float32)\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_input = Input(shape=(input_height,input_width, channels))\n",
    "f = [32, 64, 128, 256, 512]\n",
    "#inputs = keras.layers.Input((image_size, image_size, 3))\n",
    "\n",
    "## Encoder\n",
    "e0 = img_input\n",
    "e1 = stem(e0, f[0])\n",
    "e2 = residual_block(e1, f[1], strides=2)\n",
    "e3 = residual_block(e2, f[2], strides=2)\n",
    "e4 = residual_block(e3, f[3], strides=2)\n",
    "e5 = residual_block(e4, f[4], strides=2)\n",
    "\n",
    "## Bridge\n",
    "b0 = conv_block(e5, f[4], strides=1)\n",
    "b1 = conv_block(b0, f[4], strides=1)\n",
    "\n",
    "## Decoder\n",
    "u1 = upsample_concat_block(b1, e4)\n",
    "d1 = residual_block(u1, f[4])\n",
    "\n",
    "u2 = upsample_concat_block(d1, e3)\n",
    "d2 = residual_block(u2, f[3])\n",
    "\n",
    "u3 = upsample_concat_block(d2, e2)\n",
    "d3 = residual_block(u3, f[2])\n",
    "\n",
    "u4 = upsample_concat_block(d3, e1)\n",
    "d4 = residual_block(u4, f[1])\n",
    "outputs = Conv2D(n_classes, (1, 1), padding=\"same\", activation=\"relu\")(d4)\n",
    "print(outputs)\n",
    "print(n_classes)\n",
    "crf_output = CrfRnnLayer(image_dims=(input_height, input_width),\n",
    "                         num_classes=n_classes,\n",
    "                         theta_alpha=160.,\n",
    "                         theta_beta=3.,\n",
    "                         theta_gamma=3.,\n",
    "                         num_iterations=10,\n",
    "                         name='crfrnn')([outputs, img_input])\n",
    "model = get_segmentation_model(img_input, crf_output)\n",
    "model.n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5912 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5912/5912 [00:17<00:00, 338.61it/s]\n",
      "  2%|▏         | 33/1478 [00:00<00:04, 322.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Verifying validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1478/1478 [00:04<00:00, 348.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "fit\n",
      "Epoch 1/20\n",
      "5912/5912 [==============================] - 22627s 4s/step - loss: 0.6972 - accuracy: 0.7344 - val_loss: 0.5915 - val_accuracy: 0.7483\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74829, saving model to pet_class_crf.h5\n",
      "Epoch 2/20\n",
      "5912/5912 [==============================] - 20112s 3s/step - loss: 0.6409 - accuracy: 0.7586 - val_loss: 0.5405 - val_accuracy: 0.7572\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.74829 to 0.75722, saving model to pet_class_crf.h5\n",
      "Epoch 3/20\n",
      "5912/5912 [==============================] - 23391s 4s/step - loss: 0.5885 - accuracy: 0.7786 - val_loss: 0.4843 - val_accuracy: 0.7818\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.75722 to 0.78183, saving model to pet_class_crf.h5\n",
      "Epoch 4/20\n",
      "5912/5912 [==============================] - 22928s 4s/step - loss: 0.5445 - accuracy: 0.7949 - val_loss: 0.4546 - val_accuracy: 0.7974\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.78183 to 0.79738, saving model to pet_class_crf.h5\n",
      "Epoch 5/20\n",
      "5912/5912 [==============================] - 20843s 4s/step - loss: 0.5036 - accuracy: 0.8105 - val_loss: 0.4465 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.79738 to 0.81205, saving model to pet_class_crf.h5\n",
      "Epoch 6/20\n",
      "5912/5912 [==============================] - 20131s 3s/step - loss: 0.4702 - accuracy: 0.8238 - val_loss: 0.4220 - val_accuracy: 0.8089\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.81205\n",
      "Epoch 7/20\n",
      "5912/5912 [==============================] - 19549s 3s/step - loss: 0.4433 - accuracy: 0.8343 - val_loss: 0.4627 - val_accuracy: 0.7640\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.81205\n",
      "Epoch 8/20\n",
      "5912/5912 [==============================] - 18779s 3s/step - loss: 0.4168 - accuracy: 0.8446 - val_loss: 0.4574 - val_accuracy: 0.8184\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.81205 to 0.81842, saving model to pet_class_crf.h5\n",
      "Epoch 9/20\n",
      "5912/5912 [==============================] - 19898s 3s/step - loss: 0.3993 - accuracy: 0.8516 - val_loss: 0.4442 - val_accuracy: 0.8304\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.81842 to 0.83036, saving model to pet_class_crf.h5\n",
      "Epoch 10/20\n",
      "5912/5912 [==============================] - 19708s 3s/step - loss: 0.3810 - accuracy: 0.8584 - val_loss: 0.4473 - val_accuracy: 0.8256\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.83036\n",
      "Epoch 11/20\n",
      "5912/5912 [==============================] - 20999s 4s/step - loss: 0.3674 - accuracy: 0.8634 - val_loss: 0.4196 - val_accuracy: 0.8280\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.83036\n",
      "Epoch 12/20\n",
      "5912/5912 [==============================] - 20760s 4s/step - loss: 0.3554 - accuracy: 0.8679 - val_loss: 0.4208 - val_accuracy: 0.8155\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.83036\n",
      "Epoch 13/20\n",
      "5912/5912 [==============================] - 20040s 3s/step - loss: 0.3411 - accuracy: 0.8733 - val_loss: 0.5091 - val_accuracy: 0.8229\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.83036\n",
      "Epoch 14/20\n",
      "5912/5912 [==============================] - 22139s 4s/step - loss: 0.3283 - accuracy: 0.8781 - val_loss: 0.4945 - val_accuracy: 0.8279\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83036\n",
      "Epoch 15/20\n",
      "5912/5912 [==============================] - 22513s 4s/step - loss: 0.3159 - accuracy: 0.8831 - val_loss: 0.4517 - val_accuracy: 0.8311\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.83036 to 0.83108, saving model to pet_class_crf.h5\n",
      "Epoch 16/20\n",
      "5912/5912 [==============================] - 21000s 4s/step - loss: 0.3053 - accuracy: 0.8869 - val_loss: 0.4684 - val_accuracy: 0.8343\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.83108 to 0.83432, saving model to pet_class_crf.h5\n",
      "Epoch 17/20\n",
      "5912/5912 [==============================] - 20757s 4s/step - loss: 0.2938 - accuracy: 0.8910 - val_loss: 0.6650 - val_accuracy: 0.8220\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.83432\n",
      "Epoch 18/20\n",
      "5912/5912 [==============================] - 21962s 4s/step - loss: 0.2838 - accuracy: 0.8948 - val_loss: 0.4348 - val_accuracy: 0.8381\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.83432 to 0.83810, saving model to pet_class_crf.h5\n",
      "Epoch 19/20\n",
      "5912/5912 [==============================] - 21123s 4s/step - loss: 0.2770 - accuracy: 0.8973 - val_loss: 0.5098 - val_accuracy: 0.8244\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83810\n",
      "Epoch 20/20\n",
      "5912/5912 [==============================] - 20785s 4s/step - loss: 0.2666 - accuracy: 0.9013 - val_loss: 0.5046 - val_accuracy: 0.8299\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83810\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_images =  \"/Users/mavaylon/Research/Data1/train/img/\",\n",
    "    train_annotations = \"/Users/mavaylon/Research/Data1/train/ann/\",\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(glob(\"/Users/mavaylon/Research/Data1/train/img/*\")),\n",
    "    batch_size=1,\n",
    "    validate=True,\n",
    "    val_images=\"/Users/mavaylon/Research/Data1/test/img/\",\n",
    "    val_annotations=\"/Users/mavaylon/Research/Data1/test/ann/\",\n",
    "    val_batch_size=1,\n",
    "    val_steps_per_epoch=len(glob(\"/Users/mavaylon/Research/Data1/test/img/*\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
