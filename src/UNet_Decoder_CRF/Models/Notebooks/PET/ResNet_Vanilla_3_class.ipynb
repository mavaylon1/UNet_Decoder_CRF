{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "import sys\n",
    "sys.path.insert(1, '../image_segmentation_keras')\n",
    "from keras_segmentation.models.config import IMAGE_ORDERING\n",
    "\n",
    "from keras_segmentation.models.model_utils import get_segmentation_model\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 3\n",
    "input_height=256 #416\n",
    "input_width=256 #608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_conv_block(inputs, filters, pool=True, batch_norm_first=True):\n",
    "    if batch_norm_first == True:\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "    elif batch_norm_first == False:\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    if pool == True:\n",
    "        p = MaxPooling2D((2, 2))(x)\n",
    "        return [x, p]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _unet(n_classes, encoder, l1_skip_conn=True, input_height=416,\n",
    "          input_width=608):\n",
    "\n",
    "    img_input, levels = encoder(\n",
    "        input_height=input_height, input_width=input_width)\n",
    "    [f1, f2, f3, f4, f5] = levels\n",
    "    \n",
    "    print(\"f5\",f5.shape)\n",
    "\n",
    "    o = f5\n",
    "    \n",
    "    \"\"\" Bridge \"\"\"\n",
    "    o = unet_conv_block(o, 2048, pool=False)\n",
    "    \n",
    "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (concatenate([o, f4], axis=3))\n",
    "    o = unet_conv_block(o, 1024, pool=False)\n",
    "    \n",
    "    o = UpSampling2D((2, 2), interpolation=\"bilinear\")(o)\n",
    "    o = (concatenate([o, f3], axis=3))\n",
    "    o = unet_conv_block(o, 512, pool=False)\n",
    "    \n",
    "\n",
    "    o = UpSampling2D((2, 2), interpolation=\"bilinear\")(o)\n",
    "    o = (concatenate([o, f2], axis=3))\n",
    "    o = unet_conv_block(o, 256, pool=False)\n",
    "\n",
    "\n",
    "    o = UpSampling2D((2, 2), interpolation=\"bilinear\")(o)\n",
    "    o = (concatenate([o, f1], axis=3))\n",
    "    o = unet_conv_block(o, 64, pool=False)\n",
    "    \n",
    "    o = UpSampling2D((2, 2), interpolation=\"bilinear\")(o)\n",
    "    o = Conv2D(n_classes, (1, 1), padding='same',\n",
    "               data_format=IMAGE_ORDERING)(o)\n",
    "    \n",
    "    model = get_segmentation_model(img_input, o)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMAGE_ORDERING == 'channels_first':\n",
    "    MERGE_AXIS = 1\n",
    "elif IMAGE_ORDERING == 'channels_last':\n",
    "    MERGE_AXIS = -1\n",
    "\n",
    "def one_side_pad(x):\n",
    "    x = ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING)(x)\n",
    "    if IMAGE_ORDERING == 'channels_first':\n",
    "        x = Lambda(lambda x: x[:, :, :-1, :-1])(x)\n",
    "    elif IMAGE_ORDERING == 'channels_last':\n",
    "        x = Lambda(lambda x: x[:, :-1, :-1, :])(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at\n",
    "                     main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block,\n",
    "               strides=(2, 2)):\n",
    "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at\n",
    "                     main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with\n",
    "    strides=(2,2) and the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING, strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "                      strides=strides, name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "#     print(shortcut.shape)\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_resnet50_encoder(input_height,  input_width,\n",
    "                        \n",
    "                         include_top=True, \n",
    "                         input_tensor=None, input_shape=None,\n",
    "                         pooling=None,\n",
    "                         classes=1000):\n",
    "    print(input_height)\n",
    "    assert input_height % 32 == 0\n",
    "    assert input_width % 32 == 0\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_first':\n",
    "        img_input = Input(shape=(3, input_height, input_width))\n",
    "    elif IMAGE_ORDERING == 'channels_last':\n",
    "        img_input = Input(shape=(input_height, input_width, 3))\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = ZeroPadding2D((3, 3), data_format=IMAGE_ORDERING)(img_input)\n",
    "    x = Conv2D(64, (7, 7), data_format=IMAGE_ORDERING,\n",
    "               strides=(2, 2), name='conv1')(x)\n",
    "    f1 = x\n",
    "\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), data_format=IMAGE_ORDERING, strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "    f2 = one_side_pad(x)\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "    f3 = x\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "    f4 = x\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    f5 = x\n",
    "\n",
    "    return img_input, [f1, f2, f3, f4, f5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50_unet(n_classes, input_height=512, input_width=512,\n",
    "                  encoder_level=3):\n",
    "\n",
    "    model = _unet(n_classes, get_resnet50_encoder,\n",
    "                  input_height=input_height, input_width=input_width)\n",
    "    model.model_name = \"resnet50_unet\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "f5 (None, 8, 8, 2048)\n"
     ]
    }
   ],
   "source": [
    "model = resnet50_unet(n_classes=3 ,  input_height=256, input_width=256  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/Users/mavaylon/Research/pet_weights/RESNET50_VANILLA_PET/pet_class_crf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mavaylon/Research/pet_predictions/unet_vanilla_pred/1Russian_Blue_114.png\n",
      "/Users/mavaylon/Research/pet_predictions/unet_vanilla_pred/213leonberger_197.png\n",
      "/Users/mavaylon/Research/pet_predictions/unet_vanilla_pred/244samoyed_39.png\n",
      "/Users/mavaylon/Research/pet_predictions/unet_vanilla_pred/270Persian_44.png\n",
      "/Users/mavaylon/Research/pet_predictions/unet_vanilla_pred/271Egyptian_Mau_143.png\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "img_names = sorted(glob.glob(\"/Users/mavaylon/Research/pet_predictions/img/*.png\"))\n",
    "\n",
    "for name in img_names:\n",
    "    out_name = \"/Users/mavaylon/Research/pet_predictions/unet_vanilla_pred/\" + name.split('/')[-1]\n",
    "    print(out_name)\n",
    "    out = model.predict_segmentation(inp=name, out_fname=out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9b21970290>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "img=cv2.imread('/Users/mavaylon/Research/pet_predictions/unet_crf_pred/271Egyptian_Mau_143.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: <function dice_coef_loss at 0x7fa248e49d40>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-30617c91f366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mval_annotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/maavaylon/Data1/test/ann/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mval_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mval_steps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/maavaylon/Data1/test/img/*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m~/Research/CNN_CRF/LBNL_Segmentation_crf/image_segmentation_keras/keras_segmentation/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_images, train_annotations, input_height, input_width, n_classes, verify_dataset, checkpoints_path, epochs, batch_size, validate, val_images, val_annotations, val_batch_size, auto_resume_checkpoint, load_weights, steps_per_epoch, val_steps_per_epoch, gen_use_multiprocessing, ignore_zero_class, optimizer_name, do_augment, augmentation_name, callbacks, custom_augmentation, other_inputs_paths, preprocessing, read_image_type)\u001b[0m\n\u001b[1;32m    136\u001b[0m         model.compile(loss=loss_k,\n\u001b[1;32m    137\u001b[0m                       \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdice_coef_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                       metrics=['accuracy'])\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheckpoints_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CRF_CPU_Env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CRF_CPU_Env/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;31m`\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \"\"\"\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CRF_CPU_Env/lib/python3.7/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    871\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         raise ValueError('Could not interpret optimizer identifier: ' +\n\u001b[0;32m--> 873\u001b[0;31m                          str(identifier))\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret optimizer identifier: <function dice_coef_loss at 0x7fa248e49d40>"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_images =  \"/home/maavaylon/Data1/train/img/\",\n",
    "    train_annotations = \"/home/maavaylon/Data1/train/ann/\",\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(glob(\"/home/maavaylon/Data1/train/img/*\")),\n",
    "    batch_size=1,\n",
    "    validate=True,\n",
    "    val_images=\"/home/maavaylon/Data1/test/img/\",\n",
    "    val_annotations=\"/home/maavaylon/Data1/test/ann/\",\n",
    "    val_batch_size=1,\n",
    "    val_steps_per_epoch=len(glob(\"/home/maavaylon/Data1/test/img/*\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
