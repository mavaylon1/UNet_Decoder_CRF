{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers.merge import concatenate\n",
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "sys.path.insert(1, '../image_segmentation_keras')\n",
    "from keras_segmentation.models.config import IMAGE_ORDERING\n",
    "\n",
    "from keras_segmentation.models.model_utils import get_segmentation_model\n",
    "from glob import glob\n",
    "from crfrnn_layer import CrfRnnLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels, height, width = 3, 256, 256\n",
    "n_classes = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_side_pad(x):\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "    x = Lambda(lambda x: x[:, :-1, :-1, :])(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 3)\n",
      "(None, None, None, 3)\n",
      "(None, None, None, 3)\n",
      "(None, None, None, 3)\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "input_shape = (height, width, 3)\n",
    "img_input = Input(shape=input_shape)\n",
    "print(img_input.shape)\n",
    "# Add plenty of zero padding\n",
    "x = ZeroPadding2D(padding=(100, 100))(img_input)\n",
    "\n",
    "# VGG-16 convolution block 1\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='valid', name='conv1_1')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "# VGG-16 convolution block 2\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_1')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool2', padding='same')(x)\n",
    "\n",
    "# VGG-16 convolution block 3\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_1')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool3', padding='same')(x)\n",
    "pool3 = x\n",
    "\n",
    "# VGG-16 convolution block 4\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_1')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_2')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool4', padding='same')(x)\n",
    "pool4 = x\n",
    "\n",
    "# VGG-16 convolution block 5\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_1')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_2')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool5', padding='same')(x)\n",
    "\n",
    "# Fully-connected layers converted to convolution layers\n",
    "x = Conv2D(4096, (7, 7), activation='relu', padding='valid', name='fc6')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(4096, (1, 1), activation='relu', padding='valid', name='fc7')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(n_classes, (1, 1), padding='valid', name='score-fr')(x)\n",
    "\n",
    "# Deconvolution\n",
    "score2 = Conv2DTranspose(n_classes, (4, 4), strides=2, name='score2')(x)\n",
    "print(score2.shape)\n",
    "# Skip connections from pool4\n",
    "score_pool4 = Conv2D(n_classes, (1, 1), name='score-pool4')(pool4)\n",
    "score_pool4c = Cropping2D((5, 5))(score_pool4)\n",
    "score_pool4c = one_side_pad(score_pool4c)\n",
    "score_fused = Add()([score2, score_pool4c])\n",
    "score4 = Conv2DTranspose(n_classes, (4, 4), strides=2, name='score4', use_bias=False)(score_fused)\n",
    "print(score4.shape)\n",
    "\n",
    "# Skip connections from pool3\n",
    "score_pool3 = Conv2D(n_classes, (1, 1), name='score-pool3')(pool3)\n",
    "score_pool3c = Cropping2D((8, 8))(score_pool3)\n",
    "score_pool3c = one_side_pad(score_pool3c)\n",
    "\n",
    "# Fuse things together\n",
    "score_final = Add()([score4, score_pool3c])\n",
    "\n",
    "# Final up-sampling and cropping\n",
    "upsample = Conv2DTranspose(n_classes, (16, 16), strides=8, name='upsample', use_bias=False)(score_final)\n",
    "upscore = Cropping2D(((44, 44), (44, 44)))(upsample)\n",
    "print(upscore.shape)\n",
    "output = CrfRnnLayer(image_dims=(height, width),\n",
    "                     num_classes=n_classes,\n",
    "                     theta_alpha=160.,\n",
    "                     theta_beta=3.,\n",
    "                     theta_gamma=3.,\n",
    "                     num_iterations=10,\n",
    "                     name='crfrnn')([upscore, img_input])\n",
    "\n",
    "model= get_segmentation_model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/Users/mavaylon/Research/pet_weights/VGG_PAPER_CRF/pet_class_crf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5912/5912 [00:16<00:00, 364.08it/s]\n",
      "  2%|▏         | 35/1478 [00:00<00:04, 343.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Verifying validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1478/1478 [00:03<00:00, 370.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "fit\n",
      "Epoch 1/20\n",
      "5912/5912 [==============================] - 26707s 5s/step - loss: 0.4679 - accuracy: 0.8248 - val_loss: 0.3429 - val_accuracy: 0.8160\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81604, saving model to pet_class_crf.h5\n",
      "Epoch 2/20\n",
      "5912/5912 [==============================] - 26519s 4s/step - loss: 0.4675 - accuracy: 0.8253 - val_loss: 0.3322 - val_accuracy: 0.8318\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.81604 to 0.83175, saving model to pet_class_crf.h5\n",
      "Epoch 3/20\n",
      "5912/5912 [==============================] - 27251s 5s/step - loss: 0.4765 - accuracy: 0.8216 - val_loss: 0.3249 - val_accuracy: 0.8216\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.83175\n",
      "Epoch 4/20\n",
      "5912/5912 [==============================] - 26369s 4s/step - loss: 0.4556 - accuracy: 0.8299 - val_loss: 0.2364 - val_accuracy: 0.8190\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.83175\n",
      "Epoch 5/20\n",
      "5912/5912 [==============================] - 27712s 5s/step - loss: 0.5047 - accuracy: 0.8112 - val_loss: 0.2806 - val_accuracy: 0.7913\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.83175\n",
      "Epoch 6/20\n",
      "5912/5912 [==============================] - 26845s 5s/step - loss: 0.4863 - accuracy: 0.8181 - val_loss: 0.2959 - val_accuracy: 0.8255\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.83175\n",
      "Epoch 7/20\n",
      "5912/5912 [==============================] - 25761s 4s/step - loss: 0.4647 - accuracy: 0.8262 - val_loss: 0.2747 - val_accuracy: 0.8246\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.83175\n",
      "Epoch 8/20\n",
      "5912/5912 [==============================] - 26282s 4s/step - loss: 0.5049 - accuracy: 0.8112 - val_loss: 0.3582 - val_accuracy: 0.8145\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.83175\n",
      "Epoch 9/20\n",
      "5912/5912 [==============================] - 33863s 6s/step - loss: 0.4905 - accuracy: 0.8166 - val_loss: 0.3740 - val_accuracy: 0.8176\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.83175\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_images =  \"/Users/mavaylon/Research/Data1/train/img/\",\n",
    "    train_annotations = \"/Users/mavaylon/Research/Data1/train/ann/\",\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(glob(\"/Users/mavaylon/Research/Data1/train/img/*\")),\n",
    "    batch_size=1,\n",
    "    validate=True,\n",
    "    val_images=\"/Users/mavaylon/Research/Data1/test/img/\",\n",
    "    val_annotations=\"/Users/mavaylon/Research/Data1/test/ann/\",\n",
    "    val_batch_size=1,\n",
    "    val_steps_per_epoch=len(glob(\"/Users/mavaylon/Research/Data1/test/img/*\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
