{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Number of devices: 1\n",
      "conv4 (None, 16, 16, 1024)\n",
      "conv3 (None, 32, 32, 512)\n",
      "up_ (None, None, None, 512)\n",
      "(None, 32, 32, 1024)\n",
      "(None, 64, 64, 512)\n",
      "(None, 128, 128, 256)\n",
      "(None, 256, 256, 128)\n",
      "(None, 256, 256, 64)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, ZeroPadding2D, \\\n",
    "    Dropout, Conv2DTranspose, Cropping2D, Add, UpSampling2D, BatchNormalization\n",
    "from keras.layers.merge import concatenate\n",
    "from image_segmentation_keras.keras_segmentation.models.model_utils import get_segmentation_model\n",
    "from glob import glob\n",
    "import sys\n",
    "sys.path.insert(1, './src')\n",
    "from crfrnn_model import get_crfrnn_model_def\n",
    "from crfrnn_layer import CrfRnnLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope\n",
    "i=0\n",
    "if i==0:\n",
    "    input_height = 256\n",
    "    input_width = 256\n",
    "    n_classes = 3\n",
    "    channels = 3\n",
    "    \n",
    "    img_input = Input(shape=(input_height,input_width, channels))\n",
    "\n",
    "    conv0 = Conv2D(64, (3, 3), activation='relu', padding='same')(img_input)\n",
    "#     conv0 = Dropout(0.2)(conv0)\n",
    "    conv0 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv0)\n",
    "    bn0 = BatchNormalization()(conv0)\n",
    "    pool0 = MaxPooling2D((2, 2))(bn0)\n",
    "    \n",
    "    conv1 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool0)\n",
    "#     conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    bn1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(bn1)\n",
    "\n",
    "    conv2 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool1)\n",
    "#     conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    bn2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(bn2)\n",
    "\n",
    "    conv3 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool2)\n",
    "#     conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    bn3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(bn3)\n",
    "    \n",
    "    conv4 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool3)\n",
    "#     conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    print(\"conv4\",conv4.shape)\n",
    "    print('conv3',conv3.shape)\n",
    "\n",
    "    up_= Conv2DTranspose(512,(2,2),strides=2,padding='same')(conv4)\n",
    "    print('up_',up_.shape)\n",
    "    up0 = concatenate([up_, conv3], axis=3)\n",
    "    print(up0.shape)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(up0)\n",
    "#     conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    bn4 = BatchNormalization()(conv5)\n",
    "    \n",
    "    up_2= Conv2DTranspose(256,(2,2),strides=2,padding='same')(bn4)\n",
    "    up1 = concatenate([up_2, conv2], axis=-1)\n",
    "    print(up1.shape)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up1)\n",
    "#     conv6 = Dropout(0.2)(conv6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    bn5 = BatchNormalization()(conv6)\n",
    "    \n",
    "    up_3= Conv2DTranspose(128,(2,2),strides=2,padding='same')(bn5)\n",
    "    up2 = concatenate([up_3, conv1], axis=3)\n",
    "    print(up2.shape)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up2)\n",
    "#     conv7 = Dropout(0.2)(conv7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    bn6 = BatchNormalization()(conv7)\n",
    "    \n",
    "    up_4= Conv2DTranspose(64,(2,2),strides=2,padding='same')(bn6)\n",
    "    up3 = concatenate([up_4, conv0], axis=3)\n",
    "    print(up3.shape)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up3)\n",
    "#     conv8 = Dropout(0.2)(conv8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    bn7 = BatchNormalization()(conv8)\n",
    "    print(conv8.shape)\n",
    "    out = Conv2D( n_classes, (1, 1), activation='relu', padding='same')(bn7)   \n",
    "    crf_output = CrfRnnLayer(image_dims=(input_height, input_width),\n",
    "                         num_classes=n_classes,\n",
    "                         theta_alpha=160.,\n",
    "                         theta_beta=3.,\n",
    "                         theta_gamma=3.,\n",
    "                         num_iterations=10,\n",
    "                         name='crfrnn')([out, img_input])\n",
    "    model = get_segmentation_model(img_input, crf_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5912/5912 [00:19<00:00, 308.08it/s]\n",
      "  2%|▏         | 33/1478 [00:00<00:04, 325.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Verifying validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1478/1478 [00:04<00:00, 338.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "correct\n",
      "Epoch 1/20\n",
      "5912/5912 [==============================] - 17730s 3s/step - loss: 0.6694 - accuracy: 0.7411 - val_loss: 0.4883 - val_accuracy: 0.7627\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76270, saving model to pet_class_crf.h5\n",
      "Epoch 2/20\n",
      "5912/5912 [==============================] - 17760s 3s/step - loss: 0.5798 - accuracy: 0.7819 - val_loss: 0.4677 - val_accuracy: 0.7896\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.76270 to 0.78955, saving model to pet_class_crf.h5\n",
      "Epoch 3/20\n",
      "5912/5912 [==============================] - 18053s 3s/step - loss: 0.5374 - accuracy: 0.7998 - val_loss: 0.4369 - val_accuracy: 0.8063\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78955 to 0.80625, saving model to pet_class_crf.h5\n",
      "Epoch 4/20\n",
      "5912/5912 [==============================] - 18595s 3s/step - loss: 0.4879 - accuracy: 0.8200 - val_loss: 0.4273 - val_accuracy: 0.8040\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.80625\n",
      "Epoch 5/20\n",
      "5912/5912 [==============================] - 17871s 3s/step - loss: 0.4466 - accuracy: 0.8372 - val_loss: 0.4284 - val_accuracy: 0.8340\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.80625 to 0.83404, saving model to pet_class_crf.h5\n",
      "Epoch 6/20\n",
      "5912/5912 [==============================] - 17794s 3s/step - loss: 0.4128 - accuracy: 0.8509 - val_loss: 0.4650 - val_accuracy: 0.8351\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.83404 to 0.83511, saving model to pet_class_crf.h5\n",
      "Epoch 7/20\n",
      "5912/5912 [==============================] - 17817s 3s/step - loss: 0.3850 - accuracy: 0.8616 - val_loss: 0.4194 - val_accuracy: 0.8379\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.83511 to 0.83792, saving model to pet_class_crf.h5\n",
      "Epoch 8/20\n",
      "5912/5912 [==============================] - 17852s 3s/step - loss: 0.3659 - accuracy: 0.8688 - val_loss: 0.4310 - val_accuracy: 0.8384\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.83792 to 0.83844, saving model to pet_class_crf.h5\n",
      "Epoch 9/20\n",
      "5912/5912 [==============================] - 17887s 3s/step - loss: 0.3494 - accuracy: 0.8747 - val_loss: 0.4164 - val_accuracy: 0.8320\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.83844\n",
      "Epoch 10/20\n",
      "5912/5912 [==============================] - 17766s 3s/step - loss: 0.3382 - accuracy: 0.8789 - val_loss: 0.4224 - val_accuracy: 0.8213\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.83844\n",
      "Epoch 11/20\n",
      "5912/5912 [==============================] - 17704s 3s/step - loss: 0.3308 - accuracy: 0.8815 - val_loss: 0.3914 - val_accuracy: 0.8579\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.83844 to 0.85793, saving model to pet_class_crf.h5\n",
      "Epoch 12/20\n",
      "5912/5912 [==============================] - 17739s 3s/step - loss: 0.3111 - accuracy: 0.8884 - val_loss: 0.4069 - val_accuracy: 0.8560\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.85793\n",
      "Epoch 13/20\n",
      "5912/5912 [==============================] - 17723s 3s/step - loss: 0.3090 - accuracy: 0.8890 - val_loss: 0.4143 - val_accuracy: 0.8611\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.85793 to 0.86111, saving model to pet_class_crf.h5\n",
      "Epoch 14/20\n",
      "5912/5912 [==============================] - 17745s 3s/step - loss: 0.2962 - accuracy: 0.8936 - val_loss: 0.3849 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.86111\n",
      "Epoch 15/20\n",
      "5912/5912 [==============================] - 17746s 3s/step - loss: 0.2896 - accuracy: 0.8960 - val_loss: 0.4587 - val_accuracy: 0.8553\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.86111\n",
      "Epoch 16/20\n",
      "5912/5912 [==============================] - 17746s 3s/step - loss: 0.2823 - accuracy: 0.8984 - val_loss: 0.4083 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.86111 to 0.86376, saving model to pet_class_crf.h5\n",
      "Epoch 17/20\n",
      "5912/5912 [==============================] - 17761s 3s/step - loss: 0.2755 - accuracy: 0.9008 - val_loss: 0.3652 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.86376 to 0.86545, saving model to pet_class_crf.h5\n",
      "Epoch 18/20\n",
      "5912/5912 [==============================] - 18122s 3s/step - loss: 0.2626 - accuracy: 0.9053 - val_loss: 0.3623 - val_accuracy: 0.8659\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.86545 to 0.86593, saving model to pet_class_crf.h5\n",
      "Epoch 19/20\n",
      "5912/5912 [==============================] - 17663s 3s/step - loss: 0.2594 - accuracy: 0.9064 - val_loss: 0.3530 - val_accuracy: 0.8731\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.86593 to 0.87312, saving model to pet_class_crf.h5\n",
      "Epoch 20/20\n",
      "5912/5912 [==============================] - 17661s 3s/step - loss: 0.2505 - accuracy: 0.9096 - val_loss: 0.3451 - val_accuracy: 0.8725\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.87312\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_images =  \"/Users/mavaylon/Research/Data1/train/img/\",\n",
    "    train_annotations = \"/Users/mavaylon/Research/Data1/train/ann/\",\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(glob(\"/Users/mavaylon/Research/Data1/train/img/*\")),\n",
    "    batch_size=1,\n",
    "    validate=True,\n",
    "    val_images=\"/Users/mavaylon/Research/Data1/test/img/\",\n",
    "    val_annotations=\"/Users/mavaylon/Research/Data1/test/ann/\",\n",
    "    val_batch_size=1,\n",
    "    val_steps_per_epoch=len(glob(\"/Users/mavaylon/Research/Data1/test/img/*\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/Users/mavaylon/Research/pet_weights/unet_petcrf/unet__shuffled_pet_class_crf_bn_after_bothconv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
