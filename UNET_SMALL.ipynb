{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, ZeroPadding2D, \\\n",
    "    Dropout, Conv2DTranspose, Cropping2D, Add, UpSampling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras_segmentation.models.model_utils import get_segmentation_model\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    input_height = 256\n",
    "    input_width = 256\n",
    "    n_classes = 3\n",
    "    channels = 3\n",
    "\n",
    "    img_input = Input(shape=(input_height,input_width, channels))\n",
    "\n",
    "    conv0 = Conv2D(64, (3, 3), activation='relu', padding='same')(img_input)\n",
    "    conv0 = Dropout(0.2)(conv0)\n",
    "    conv0 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv0)\n",
    "    pool0 = MaxPooling2D((2, 2))(conv0)\n",
    "    \n",
    "    conv1 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool0)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "    up1 = concatenate([UpSampling2D((2, 2))(conv3), conv2], axis=-1)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(up1)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up2 = concatenate([UpSampling2D((2, 2))(conv4), conv1], axis=-1)\n",
    "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(up2)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    up3 = concatenate([UpSampling2D((2, 2))(conv5), conv0], axis=-1)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(up3)\n",
    "    conv6 = Dropout(0.2)(conv6)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    out = Conv2D( n_classes, (1, 1) , padding='same')(conv6)\n",
    "\n",
    "    model = get_segmentation_model(img_input ,  out ) # this would build the segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5912 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5912/5912 [00:19<00:00, 310.72it/s]\n",
      "  2%|▏         | 27/1478 [00:00<00:05, 265.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Verifying validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1478/1478 [00:05<00:00, 276.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "hello_pet\n",
      "Epoch 1/20\n",
      "5912/5912 [==============================] - 8908s 2s/step - loss: 0.7929 - accuracy: 0.6518 - val_loss: 0.7328 - val_accuracy: 0.6816\n",
      "\n",
      "Epoch 00001: saving model to pet_class_crf.h5\n",
      "Epoch 2/20\n",
      "5912/5912 [==============================] - 8887s 2s/step - loss: 0.7474 - accuracy: 0.6725 - val_loss: 0.7015 - val_accuracy: 0.7091\n",
      "\n",
      "Epoch 00002: saving model to pet_class_crf.h5\n",
      "Epoch 3/20\n",
      "5912/5912 [==============================] - 8902s 2s/step - loss: 0.6973 - accuracy: 0.7006 - val_loss: 0.6278 - val_accuracy: 0.7223\n",
      "\n",
      "Epoch 00003: saving model to pet_class_crf.h5\n",
      "Epoch 4/20\n",
      "5912/5912 [==============================] - 8895s 2s/step - loss: 0.6658 - accuracy: 0.7189 - val_loss: 0.6291 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00004: saving model to pet_class_crf.h5\n",
      "Epoch 5/20\n",
      "5912/5912 [==============================] - 8981s 2s/step - loss: 0.6473 - accuracy: 0.7280 - val_loss: 0.6390 - val_accuracy: 0.7514\n",
      "\n",
      "Epoch 00005: saving model to pet_class_crf.h5\n",
      "Epoch 6/20\n",
      "5912/5912 [==============================] - 8909s 2s/step - loss: 0.6351 - accuracy: 0.7353 - val_loss: 0.6221 - val_accuracy: 0.7531\n",
      "\n",
      "Epoch 00006: saving model to pet_class_crf.h5\n",
      "Epoch 7/20\n",
      "5836/5912 [============================>.] - ETA: 1:50 - loss: 0.6280 - accuracy: 0.7418"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_images =  \"/Users/mavaylon/Research/image-segmentation-keras/Data/train/img/\",\n",
    "    train_annotations = \"/Users/mavaylon/Research/image-segmentation-keras/Data/train/ann/\",\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(glob(\"/Users/mavaylon/Research/image-segmentation-keras/Data/train/img/*\")),\n",
    "    batch_size=1,\n",
    "    validate=True,\n",
    "    val_images=\"/Users/mavaylon/Research/image-segmentation-keras/Data/test/img/\",\n",
    "    val_annotations=\"/Users/mavaylon/Research/image-segmentation-keras/Data/test/ann/\",\n",
    "    val_batch_size=1,\n",
    "    val_steps_per_epoch=len(glob(\"/Users/mavaylon/Research/image-segmentation-keras/Data/test/img/*\"))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
